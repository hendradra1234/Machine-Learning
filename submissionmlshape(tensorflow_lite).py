# -*- coding: utf-8 -*-
"""SubmissionMLShape(tensorflow_lite).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10CzhPpemZAkN60_veDJCWH1byyxA8X8x
"""

import os
from google.colab import drive
drive.mount('/content/gdrive')
os.environ['KAGGLE_CONFIG_DIR'] = '/content/gdrive/My Drive/Kaggle'

cd /content/gdrive/My Drive/Kaggle

pwd

!kaggle datasets download -d smeschke/four-shapes

#Extract Dataset
import zipfile as zf

try:
  dataset = 'four-shapes.zip'
  extract_directory = 'dataset/shape/'

  extract_dataset = zf.ZipFile(dataset)
  extract_dataset.extractall(extract_directory)
  extract_dataset.close()
  print('ekstraksi dataset selesai')
  
except(FileNotFoundError,FileExistsError):
  print('Dataset tidak ditemukan')
except:
  print('terjadi kesalahan')
finally:
  print('End the process')

#listing and get data from dataset
import os
directory = 'dataset/'
MainDir = os.path.join(directory,'shape/shapes')
MainDirlist = os.listdir(MainDir)

print(MainDirlist)

print('\n list data {}'.format(MainDir))

classLen = []
dirlist = []

for i in MainDirlist:
    dir = os.path.join(MainDir,i)
    print('directory {}'.format(dir))
    dirlist.append(dir)
    dirQty = len(os.listdir(dir))
    print('{} data'.format(dirQty))

    classLen.append(dirQty)
    
print('Total image data : {}'.format(sum(classLen)))

circle_data = os.listdir(dirlist[0])
square_data = os.listdir(dirlist[1])
star_data = os.listdir(dirlist[2])
triagle_data = os.listdir(dirlist[3])

classQty = len(MainDirlist)
className = MainDirlist
print('Class Name : {}'.format(className))
print('Class Qty  : {}'.format(classQty))

#Image Evaluation
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

show = 1

try:
  circle = [os.path.join(dirlist[0],fname)for fname in circle_data[show-1:show]]
  square = [os.path.join(dirlist[1],fname)for fname in square_data[show-1:show]]
  star = [os.path.join(dirlist[2],fname) for fname in star_data[show-1:show]]
  triagle = [os.path.join(dirlist[3],fname) for fname in triagle_data[show-1:show]]

  for i,img_path in enumerate(circle + square + star + triagle):

    print('class {}'.format(className[i]))
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.colorbar()
    plt.axis('off')
    plt.show()
except(FileExistsError,FileNotFoundError):
  print('directory tidak valid')
 
finally:
  print('\n operation terminated\n')

import matplotlib.pyplot as plt

size = classLen
labels = MainDirlist

plt.pie(
    size,
    labels=labels,
    autopct='%.1f%%',
    shadow=True,
    pctdistance=0.85,
    labeldistance=1.05,
    startangle=20,
    explode=[0 if 1 > 0 else 0.2 for i in range(len(size))]
)
plt.axis('equal')
plt.show()

#dataset Preprocessing
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator

batchsize = 128
img_w = 150
img_h = 150


datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)


trainDatagen = datagen.flow_from_directory(
  MainDir,
  batch_size = batchsize,
  target_size=(img_w,img_h),
  shuffle=True,
  class_mode='categorical',
  interpolation='nearest',
  subset='training'
)


validationDatagen = datagen.flow_from_directory(
    MainDir,
    batch_size = batchsize,
    target_size=(img_w,img_h),
    shuffle=True,
    class_mode='categorical',
    interpolation='nearest',
    subset='validation'
)

classind = trainDatagen.class_indices
classmode = trainDatagen.class_mode
shape = trainDatagen.image_shape

print(classind)
print(classmode)
print(shape)

from tensorflow import keras
from tensorflow.keras.layers import Dropout
from keras.layers import BatchNormalization
from tensorflow.keras.layers.experimental.preprocessing import Rescaling


color = 3


model = keras.models.Sequential()

model.add(keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(img_w,img_h,color)))
model.add(keras.layers.MaxPool2D(2,2))

model.add(keras.layers.Conv2D(256,(3,3),padding='same',activation='relu'))
model.add(keras.layers.MaxPool2D(2,2))

model.add(keras.layers.Conv2D(512,(3,3),padding='same',activation='relu'))
model.add(keras.layers.MaxPool2D(2,2))

model.add(keras.layers.Conv2D(1024,(3,3),padding='same',activation='relu'))
model.add(keras.layers.MaxPool2D(2,2))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(1024,activation='relu'))
model.add(keras.layers.Dense(512,activation='relu'))
model.add(keras.layers.Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(keras.layers.Dense(classQty,activation='softmax'))


model.compile(
    loss = tf.keras.losses.CategoricalCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(lr=0.0001),
    metrics = ['accuracy']

)

model.summary()

#fit model
import datetime
import tensorboard as tb

log_dir = 'logs/fit/'+ datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
file_writer = tf.summary.create_file_writer('/path/to/logs')
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)

ACC_TRESHOLD = 0.98
ACC_val = 0.92

class Callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self,epoch,logs={}):
    if(logs.get('accuracy') > ACC_TRESHOLD) and (logs.get('val_accuracy') > ACC_val ):
      print('\n akurasi mencapai {}&'.format(ACC_TRESHOLD*100))
      self.model.stop_training = True

earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=5)


acc_stop = Callback()
saveLog = tf.keras.callbacks.CSVLogger('OCTmodel(tf_lite)Log.csv',separator=',',append=False)

with tf.device('/device:GPU:0'):
  histSave =  model.fit(
      trainDatagen,
      epochs = 50,
      batch_size = batchsize,
      validation_data = validationDatagen,
      callbacks=[acc_stop,saveLog,tensorboard_callback],
      steps_per_epoch = 20,
      verbose=1,
      validation_steps=3
  )
   
model.save('Shapemodel(tf_lite).h5')

print('Training selesai')

#tensorflow lite deployed saved model

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
savename = 'ShapelassificationModel.tflite'
filesave = os.path.join('/content/gdrive/My Drive/Kaggle/',savename)

open(filesave,'wb').write(tflite_model)

#plotting acc
import datetime
import matplotlib.pyplot as plt

acc = histSave.history['accuracy']
epoch = range(len(acc))
val_acc = histSave.history['val_accuracy']
val_loss = histSave.history['val_loss']
loss = histSave.history['loss']

plt.figure(figsize=(15,5))
plt.plot(epoch,acc,label='Training Accuracy')
plt.plot(epoch,loss,label='Training Loss')
plt.plot(epoch,val_acc,label='validation Acurracy')
plt.plot(epoch,val_loss,label='validation Loss')
plt.title('Plot Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

#Prediction
import os
from google.colab import files
from keras.preprocessing import image
import numpy as np


def predict():
  try:
  
    uploaded = files.upload()
    idx = 0
    CLASS = className

    for fn in uploaded.keys():
      path = fn
      img = image.load_img(path, target_size=(img_w,img_h))
      imgArr = image.img_to_array(img)
      imgArr = np.expand_dims(imgArr,axis=0)
  
    img = mpimg.imread(path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

    images = np.vstack([imgArr])
    predict = model.predict(images,batch_size=10)

    if predict[0,0] == 1:
       idx = 0
    elif predict[0,1] == 1:
      idx = 1
    elif predict[0,2] == 1:
      idx = 2
    elif predict[0,3] == 1:
      idx = 3

    print('Predict : {}'.format(CLASS[idx]))
  except:
    print('Predict gagal')

predict()

predict()

predict()

predict()